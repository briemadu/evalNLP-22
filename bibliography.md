---
title: Bibliography
layout: default
navigation_weight: 2
---
## :books: Bibliography :books:

Each week we will have its corresponding reading list available on Moodle and in the [schedule](./schedule). Here is an overview of the relevant literature. 

Books & book chapters

* DROR, Rotem; PELED-COHEN, Lotem; SHLOMOV, Segev & REICHART, Roi. Statistical Significance Testing for Natural Language Processing. Synthesis Lectures on Human Language Technologies, v. 13, n. 2, p. 1-116, 2020. [link](https://www.morganclaypool.com/doi/abs/10.2200/S00994ED1V01Y202002HLT045?casa_token=sFwy5BwuTSYAAAAA:wfzPR418bHmo7Pt_T1LEzL2SSVI648i2MIFGFEwNK1NKglsjq8cOYMRfHmPCk8Qo0EsW4pi9vvij)
* GALLIERS, Julia R.; SPÄRCK JONES, Karen. Evaluating natural language processing systems. University of Cambridge, Computer Laboratory, 1993.
* HIRSCHMAN, Lynette; THOMPSON, Henry S. Overview of evaluation in speech and natural language processing. In: Survey of the state of the art in human language technology. Cambridge University Press, 1997. p. 409-414.
* RESNIK, Philip & LIN, Jimmy. Evaluation of NLP Systems. In: Clark, Alexander; Fox, Chris & Lappin, Shalom (Eds.). The handbook of computational linguistics and natural language processing. John Wiley & Sons, pp. 271-295, 2010.
* (*Experimentation*, Appendix B of) SMITH, Noah A. Linguistic Structure Prediction. Synthesis Lectures on Human Language Technologies, v. 4, n. 2, 2011.
[link](https://doi.org/10.2200/S00361ED1V01Y201105HLT013)
* SPÄRCK JONES, Karen & GALLIERS, Julia R. Evaluating Natural Language Processing Systems: An Analysis and Review. Berlin: Springer, 1996. [link](https://opac.ub.uni-potsdam.de/DB=1/SET=3/TTL=2/SHW?FRST=1)


Papers

* BARR, Valerie; KLAVANS, Judith L. Verification and validation of language processing systems: is it evaluation?. In: Proceedings of the ACL 2001 Workshop on Evaluation Methodologies for Language and Dialogue Systems. 2001. [link](https://www.aclweb.org/anthology/W01-0906.pdf)
* BELINKOV, Yonatan & GLASS, James. Analysis methods in neural language processing: A survey. Transactions of the Association for Computational Linguistics, v. 7, p. 49-72, 2019. [link](https://www.aclweb.org/anthology/Q19-1004.pdf)
* BELZ, Anja. That's nice… what can you do with it?. Computational Linguistics, v. 35, n. 1, p. 111-118, 2009.
* BENDER, Emily M.; FRIEDMAN, Batya. Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, v. 6, p. 587-604, 2018. [link](https://www.mitpressjournals.org/doi/pdfplus/10.1162/tacl_a_00041)
* BERG-KIRKPATRICK, Taylor; BURKETT, David; KLEIN, Dan. An empirical investigation of statistical significance in nlp. In: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, p. 995-1005, 2012. [link](https://www.aclweb.org/anthology/D12-1091.pdf)
* DROR, Rotem; BAUMER, Gili; BOGOMOLOV, Marina & REICHART, Roi. Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets. Transactions of the Association for Computational Linguistics, v. 5, p. 471-486, 2017. [link](https://www.aclweb.org/anthology/Q17-1033.pdf)
* DROR, R., BAUMER, G., SHLOMOV, S., & REICHART, R. The hitchhiker’s guide to testing statistical significance in natural language processing. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), p. 1383-1392, 2018. [link](https://www.aclweb.org/anthology/P18-1128/)
* ESCARTÍN, Carla Parra et al. Ethical Considerations in NLP Shared Tasks. In: Proceedings of the First ACL Workshop on Ethics in Natural Language Processing. 2017. p. 66-73. [link](https://www.aclweb.org/anthology/W17-1608.pdf)
* FORT, Karën; ADDA, Gilles; COHEN, K. Bretonnel. Amazon mechanical turk: Gold mine or coal mine?. Computational Linguistics, v. 37, n. 2, p. 413-420, 2011. [link](https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00057)
* GORMAN, Kyle; BEDRICK, Steven. We need to talk about standard splits. In: Proceedings of the 57th annual meeting of the association for computational linguistics. 2019. p. 2786-2791. [link](https://www.aclweb.org/anthology/P19-1267.pdf)
* HOVY, Dirk; SPRUIT, Shannon L. The social impact of natural language processing. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2016. p. 591-598. [link](https://www.aclweb.org/anthology/P16-2096.pdf)
* KING, Margaret. Evaluating natural language processing systems. Communications of the ACM, v. 39, n. 1, p. 73-79, 1996. [link](https://dl.acm.org/doi/abs/10.1145/234173.234208?casa_token=CwCV7waCKFIAAAAA:xhvxEl6RDm57vO0Oq9kqhCFWbAGz5yrdi0d9RlLnb-sRM8l4fEMaJhPcuXfkd0ps5yREAxvQDHrt)
* NOVIKOVA, Jekaterina et al. Why We Need New Evaluation Metrics for NLG. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, p. 2241-2252, 2017. [link](https://www.aclweb.org/anthology/D17-1238/)
* PAROUBEK, Patrick; CHAUDIRON, Stéphane & HIRSCHMAN, Lynette. Principles of Evaluation in Natural Language Processing. Traitement Automatique des Langues, ATALA, 48 (1), pp.7-31. hal- 00502700, 2007.
* SØGAARD, Anders; JOHANNSEN, Anders; PLANK, Barbara; HOVY, Dirk & MARTINEZ, Hector. What’s in a p-value in NLP?. In: Proceedings of the eighteenth conference on computational natural language learning, p. 1-10, 2014. [link](https://www.aclweb.org/anthology/W14-1601.pdf)
* SPÄRCK JONES, Karen. Towards better NLP system evaluation. In: Human Language Technology: Proceedings of a Workshop held at Plainsboro, New Jersey, March 8-11, 1994. [link](https://www.aclweb.org/anthology/H94-1018.pdf)
* VAN DER LEE, C., GATT, A., VAN MILTENBURG, E., WUBBEN, S., & KRAHMER, E.  Best practices for the human evaluation of automatically generated text. In: Proceedings of the 12th International Conference on Natural Language Generation, p. 355-368, 2019. [link](https://www.aclweb.org/anthology/W19-8643.pdf)


Miscellaneous

* COHEN, Paul R.; HOWE, Adele E. How evaluation guides AI research: The message still counts more than the medium. AI magazine, v. 9, n. 4, p. 35-35, 1988. [link](https://doi.org/10.1609/aimag.v9i4.952)
* HUYEN, Chip. Evaluation Metrics for Language Modeling. Blogpost, 2019. [link](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/)
* KING, Margaret. Evaluating natural language processing systems. Communications of the ACM, v. 39, n. 1, p. 73-79, 1996. [link](https://dl.acm.org/doi/abs/10.1145/234173.234208?casa_token=8KZTFYtxcXoAAAAA:x71qSj6riN8FnypzsDWZ3n8qIV8b0C5H14ToxWdQlLAYMqbWytVdAxmELv0QhyvuYfgCFFHhcYK_)
* KING M., Maegaard B., Schütz J., des Tombes L., Bech A., Neville A., Arppe A., Balkan L., Brace C., Bunt H., Carlson L., Douglas S., Höge M., Krauwer S., Manzi S., Mazzi, C., Sieleman A. J., Steenbakkers R. EAGLES Evaluation of Natural Language Processing Systems: Final Report. EAGLES Document EAGEWG-PR. 2. Center for Sprogteknologi, Copenhagen, 1996. [link](https://www.issco.unige.ch/en/research/projects/ewg96/node1.html)
* LIPTON, Zachary C.; STEINHARDT, Jacob. Troubling trends in machine learning scholarship. Queue, v. 17, n. 1, p. 45-77, 2019. [link](https://queue.acm.org/detail.cfm?id=3328534)
* POTTS, Christopher. Evaluation methods and metrics in NLP. 2020. [link](https://nbviewer.jupyter.org/github/cgpotts/cs224u/blob/master/evaluation_methods.ipynb) and [link](https://nbviewer.jupyter.org/github/cgpotts/cs224u/blob/master/evaluation_metrics.ipynb)
* REITER, Ehud. His blog has several posts related to evaluation. [link](https://ehudreiter.com/)
